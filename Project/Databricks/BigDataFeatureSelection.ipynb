{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9c69ab96-f955-4fc7-bf07-b7952c5d9212","showTitle":false,"title":""}},"source":["# Team information\n","|S. No|Name|email|\n","|-|-|-|\n","|1|Mathews Roy|psymr3@nottingham.ac.uk|\n","|2|Ewan Ross|psyer1@nottingham.ac.uk|\n","|3|Soham Talukdar|ppxst3@nottingham.ac.uk|\n","|4|Srushanth Baride|ppxsb5@nottingham.ac.uk|"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c79c08dd-a6e8-497f-8579-1a08a01049e3","showTitle":false,"title":""}},"source":["# Resources used\n","[pyspark: Extracting, transforming and selecting features](https://spark.apache.org/docs/latest/ml-features)</br>\n","[sklearn mutual_info_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html)</br>\n","[sklearn chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html?highlight=chi2#sklearn.feature_selection.chi2)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"28e89759-109b-4848-bdbb-fe8220267a42","showTitle":false,"title":""}},"source":["# Data processing & plot libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e0e0b0e9-3225-40be-9c0a-601a14577abc","showTitle":false,"title":""}},"outputs":[],"source":["import time\n","import pandas as pd\n","from sklearn import metrics\n","from datetime import timedelta\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c0d5a9ca-dcad-490d-9d48-1f1becc546a0","showTitle":false,"title":""}},"source":["# pyspark ML libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b024af5c-e7cf-4beb-b032-865c388a5e2c","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.ml.linalg import Vectors\n","from pyspark.ml.feature import UnivariateFeatureSelector\n","from pyspark.ml.feature import ChiSqSelector, VectorAssembler\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.classification import DecisionTreeClassifier as pyspark_DecisionTreeClassifier"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ae7e0e9f-316f-4d5c-879b-148ee753e5fe","showTitle":false,"title":""}},"source":["# sklearn ML libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b99bea6e-bf6c-4256-b852-63b27f6ba9e3","showTitle":false,"title":""}},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression\n","from sklearn.tree import DecisionTreeClassifier as sklearn_DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5d37ccd0-2ee8-4491-805b-2a2dc50dcadc","showTitle":false,"title":""}},"outputs":[],"source":["# Creating a new spark session\n","spark = SparkSession.builder.master(\"local[*]\").appName(\"MLlib lab\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5c92c353-2d50-4570-8f45-1b54c8e41201","showTitle":false,"title":""}},"outputs":[],"source":["# Path to the Leukemia csv file\n","_leukemia_dataset_file = \"../Datasets/Leukemia_GSE9476.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"bfc07dff-00c7-447e-bf81-6351e5774d2a","showTitle":false,"title":""}},"outputs":[],"source":["'''\n","Read data from Leukemia csv file\n","Max columns are set to 22285\n","Header is set to True as the csv file contains a header\n","'''\n","sparkDF = spark.read.option(\"maxColumns\", 22285).csv(_leukemia_dataset_file, header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"aadc4237-4433-43ef-89dc-290ba3cef045","showTitle":false,"title":""}},"outputs":[],"source":["# Converting spark DataFrame to pandas DataFrame for easy processing\n","pandasDF = sparkDF.toPandas()\n","pandasDF.head()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a5978144-1d23-4f7c-b048-3498e5df51b9","showTitle":false,"title":""}},"source":["[Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"36c5d54c-3e1a-44a8-b716-51860629a139","showTitle":false,"title":""}},"outputs":[],"source":["# Getting the DataFrame shape\n","# The data is suffering the 'curse of dimensionality' as the no.of features are exponentially greater than the no.of samples\n","pandasDF.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a15b2f91-7ea5-4a01-875e-61add6c74147","showTitle":false,"title":""}},"outputs":[],"source":["bone_marrow_type = pandasDF[\"type\"].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ee8923ef-be0e-4e29-9565-8575b9d3421f","showTitle":false,"title":""}},"outputs":[],"source":["# Converting string categorical to numerical\n","LE = LabelEncoder()\n","pandasDF['type'] = LE.fit_transform(pandasDF['type'])\n","pandasDF['type'] = pandasDF['type'].astype('int32')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8ec56c40-7660-4342-95f5-2fdb0c049fb6","showTitle":false,"title":""}},"outputs":[],"source":["# Converting pandas DataFrame to spark DataFrame\n","sparkDF = spark.createDataFrame(pandasDF)\n","\n","# Converting spark DataFrame columns to float\n","sparkDF = sparkDF.select(*(F.col(c).cast(\"float\").alias(c) for c in sparkDF.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"75896565-7702-40e7-82a3-8c290dd4428f","showTitle":false,"title":""}},"outputs":[],"source":["# Vectorising the spark DataFrame for easier processing\n","vecAssembler = VectorAssembler(inputCols=sparkDF.columns, outputCol=\"features\")\n","vector_sparkDF = vecAssembler.transform(sparkDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ca3adc43-2f11-4434-bd0b-e02cf98eb62a","showTitle":false,"title":""}},"outputs":[],"source":["# Setting features split\n","features_mul = 4000"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d5130960-f16b-477f-a804-201548701d96","showTitle":false,"title":""}},"source":["# spark [ChiSqSelector](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.ChiSqSelector.html)\n","[ChiSqSelector](https://george-jen.gitbook.io/data-science-and-apache-spark/chisqselector) stands for Chi-Squared feature selection. It operates on labeled data with categorical features. ChiSqSelector uses the Chi-Squared test of independence to decide which features to choose."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fb433705-ee12-4310-9b8c-b58099cd94af","showTitle":false,"title":""}},"outputs":[],"source":["'''\n","Function: spark_ChiSqSelector\n","INPUT:\n","------\n","i: Number of Features to select\n","_vector_sparkDF: DataFrame from which the Features will be selected\n","\n","OUTPUT:\n","-------\n","1. Model accuracy\n","2. Execution time for feature selection, building and evaluating the model\n","'''\n","\n","def spark_ChiSqSelector(i, _vector_sparkDF):\n","  # Start time for execution time\n","  start_time = time.monotonic()\n","  \n","  # Selecting the best i features from the entire dataset\n","  selector = ChiSqSelector(\n","    numTopFeatures=i, \n","    featuresCol=\"features\", \n","    outputCol=\"selectedFeatures\", \n","    labelCol=\"type\"\n","  )\n","  result = selector.fit(_vector_sparkDF).transform(_vector_sparkDF)\n","  print(f\"Top {selector.getNumTopFeatures()} features selected\")\n","  \n","  # Splitting the data into training & testing\n","  (train, test) = result.randomSplit([0.7, 0.3])\n","  \n","  # Using pyspark DecisionTreeClassifier to define and fit the ML model\n","  dt = pyspark_DecisionTreeClassifier(labelCol=\"type\", featuresCol=\"selectedFeatures\")\n","  model = dt.fit(train)\n","  \n","  # Make predictions\n","  predictions = model.transform(test)\n","  \n","  # Evaluating the predictions\n","  evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"type\", \n","    predictionCol=\"prediction\", \n","    metricName=\"accuracy\"\n","  )\n","  accuracy = evaluator.evaluate(predictions)\n","  print(f\"Test accuracy = {accuracy}\")\n","  \n","  # End time for execution time\n","  end_time = time.monotonic()\n","  \n","  # Return accuracy and execution time\n","  return accuracy, timedelta(seconds=end_time - start_time).total_seconds()\n","  "]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ffc1bc10-a813-4616-bf8d-c38f2be72845","showTitle":false,"title":""}},"source":["# spark [UnivariateFeatureSelector](https://spark.apache.org/docs/latest/ml-features#univariatefeatureselector)\n","[UnivariateFeatureSelector](https://spark.apache.org/docs/latest/ml-features#univariatefeatureselector) operates on categorical/continuous labels with categorical/continuous features. User can set featureType and labelType, and Spark will pick the score function to use based on the specified featureType and labelType."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"33848260-35fd-498d-95ed-3f5c6956819d","showTitle":false,"title":""}},"outputs":[],"source":["'''\n","Function: spark_UnivariateFeatureSelector\n","INPUT:\n","------\n","i: Number of Features to select\n","_vector_sparkDF: DataFrame from which the Features will be selected\n","\n","OUTPUT:\n","-------\n","1. Model accuracy\n","2. Execution time for feature selection, building and evaluating the model\n","'''\n","\n","def spark_UnivariateFeatureSelector(i, _vector_sparkDF):\n","  # Start time for execution time\n","  start_time = time.monotonic()\n","  \n","  # Selecting the best i features from the entire dataset\n","  selector = UnivariateFeatureSelector(\n","    featuresCol=\"features\", \n","    outputCol=\"selectedFeatures\", \n","    labelCol=\"type\", \n","    selectionMode=\"numTopFeatures\"\n","  )\n","  selector.setFeatureType(\"continuous\").setLabelType(\"categorical\").setSelectionThreshold(i)\n","  result = selector.fit(_vector_sparkDF).transform(_vector_sparkDF)\n","\n","  print(\"UnivariateFeatureSelector output with top %d features selected using f_classif\" % selector.getSelectionThreshold())\n","  # result.show()\n","  \n","  # Splitting the data into training & testing\n","  (train, test) = result.randomSplit([0.7, 0.3])\n","  \n","  # Using pyspark DecisionTreeClassifier to define and fit the ML model\n","  dt = pyspark_DecisionTreeClassifier(labelCol=\"type\", featuresCol=\"selectedFeatures\")\n","  model = dt.fit(train)\n","  \n","  # Make predictions\n","  predictions = model.transform(test)\n","  \n","  # Evaluating the predictions\n","  evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"type\", \n","    predictionCol=\"prediction\", \n","    metricName=\"accuracy\"\n","  )\n","  accuracy = evaluator.evaluate(predictions)\n","  print(f\"Test accuracy = {accuracy}\")\n","  \n","  # End time for execution time\n","  end_time = time.monotonic()\n","  \n","  # Return accuracy and execution time\n","  return accuracy, timedelta(seconds=end_time - start_time).total_seconds()\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"62949702-a7a4-46c6-87a9-49f69c913451","showTitle":false,"title":""}},"outputs":[],"source":["spark_acc_ChiSqSelector = []\n","spark_time_ChiSqSelector = []\n","spark_acc_UnivariateFeatureSelector = []\n","spark_time_UnivariateFeatureSelector = []\n","\n","for i in range(2, len(vector_sparkDF.columns), features_mul):\n","  acc, exec_time = spark_ChiSqSelector(i, vector_sparkDF)\n","  spark_acc_ChiSqSelector.append(acc)\n","  spark_time_ChiSqSelector.append(exec_time)\n","  \n","  acc, exec_time = spark_UnivariateFeatureSelector(i, vector_sparkDF)\n","  spark_acc_UnivariateFeatureSelector.append(acc)\n","  spark_time_UnivariateFeatureSelector.append(exec_time)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d449e0da-06c7-48b3-834a-db04ef76cf40","showTitle":false,"title":""}},"source":["# sklearn [chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)\n","[ChiSqSelector](https://george-jen.gitbook.io/data-science-and-apache-spark/chisqselector) stands for Chi-Squared feature selection. It operates on labeled data with categorical features. ChiSqSelector uses the Chi-Squared test of independence to decide which features to choose."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b12bd75c-fdbb-448c-802f-31aad65616e3","showTitle":false,"title":""}},"outputs":[],"source":["# X is features\n","X = pandasDF[pandasDF.columns.drop('type')]\n","\n","# y is labels\n","y = pandasDF['type']"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2c6076c8-7701-4103-9f32-bdcf5737653a","showTitle":false,"title":""}},"outputs":[],"source":["'''\n","Function: sklearn_chi2\n","INPUT:\n","------\n","i: Number of Features to select\n","_X: Features\n","_y: labels\n","\n","OUTPUT:\n","-------\n","1. Model accuracy\n","2. Execution time for feature selection, building and evaluating the model\n","'''\n","\n","def sklearn_chi2(i, _X, _y):\n","  # Start time for execution time\n","  start_time = time.monotonic()\n","  \n","  # Selecting the best i features from the entire dataset\n","  X_new = SelectKBest(chi2, k=i).fit_transform(_X, _y)\n","  \n","  # Splitting the data into training & testing\n","  train, test, train_labels, test_labels = train_test_split(X_new, _y, test_size=0.30, random_state=42)\n","  \n","  # Using sklearn DecisionTreeClassifier to define and fit the ML model\n","  clf = sklearn_DecisionTreeClassifier()\n","  clf = clf.fit(train, train_labels)\n","  \n","  # Make predictions\n","  predictions = clf.predict(test)\n","  \n","  # Evaluating the predictions\n","  accuracy = metrics.accuracy_score(test_labels, predictions)\n","  print(f\"Test accuracy = {accuracy}\")\n","  \n","  # End time for execution time\n","  end_time = time.monotonic()\n","  \n","  # Return accuracy and execution time\n","  return accuracy, timedelta(seconds=end_time - start_time).total_seconds()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a9eb2a29-2eee-4f4e-9737-3018921739e6","showTitle":false,"title":""}},"source":["# sklearn [mutual_info_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html?highlight=mutual_info_regression#sklearn.feature_selection.mutual_info_regression)\n","[Estimate mutual information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html?highlight=mutual_info_regression#sklearn.feature_selection.mutual_info_regression) for a continuous target variable.</br>\n","Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</br>\n","The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d93f5c1f-618e-4d54-869d-3d28e00bbebf","showTitle":false,"title":""}},"outputs":[],"source":["'''\n","Function: sklearn_mutual_info_regression\n","INPUT:\n","------\n","i: Number of Features to select\n","_X: Features\n","_y: labels\n","\n","OUTPUT:\n","-------\n","1. Model accuracy\n","2. Execution time for feature selection, building and evaluating the model\n","'''\n","\n","def sklearn_mutual_info_regression(i, _X, _y):\n","  # Start time for execution time\n","  start_time = time.monotonic()\n","  \n","  # Selecting the best i features from the entire dataset\n","  selector = SelectKBest(mutual_info_regression, k=i)\n","  selector.fit(_X, _y)\n","  \n","  X_new = X[X.columns[selector.get_support()]]\n","  \n","  # Splitting the data into training & testing\n","  train, test, train_labels, test_labels = train_test_split(X_new, _y, test_size=0.30, random_state=42)\n","  \n","  # Using sklearn DecisionTreeClassifier to define and fit the ML model\n","  clf = sklearn_DecisionTreeClassifier()\n","  clf = clf.fit(train, train_labels)\n","  \n","  # Make predictions\n","  predictions = clf.predict(test)\n","  \n","  # Evaluating the predictions\n","  accuracy = metrics.accuracy_score(test_labels, predictions)\n","  print(f\"Test accuracy = {accuracy}\")\n","  \n","  # End time for execution time\n","  end_time = time.monotonic()\n","  \n","  # Return accuracy and execution time\n","  return accuracy, timedelta(seconds=end_time - start_time).total_seconds()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1a67455b-947c-49e5-876a-fcaa9d89e562","showTitle":false,"title":""}},"outputs":[],"source":["sklearn_acc_chi2 = []\n","sklearn_time_chi2 = []\n","sklearn_acc_mutual_info_regression = []\n","sklearn_time_mutual_info_regression = []\n","\n","for i in range(2, X.columns.size, features_mul):\n","  acc, exec_time = sklearn_chi2(i, X, y)\n","  sklearn_acc_chi2.append(acc)\n","  sklearn_time_chi2.append(exec_time)\n","  \n","  acc, exec_time = sklearn_mutual_info_regression(i, X, y)\n","  sklearn_acc_mutual_info_regression.append(acc)\n","  sklearn_time_mutual_info_regression.append(exec_time)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d76b1e5d-1d33-422c-847c-1f1b1727da82","showTitle":false,"title":""}},"source":["# Visualisation"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7b9d7c21-16a0-41a2-bb68-6275f06fb434","showTitle":false,"title":""}},"outputs":[],"source":["x_axis = list([i for i in range(2, X.columns.size, features_mul)])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8be717ff-1cf0-4e51-902f-9cac5a20c492","showTitle":false,"title":""}},"outputs":[],"source":["plt.plot(x_axis, spark_acc_ChiSqSelector, label='spark_ChiSqSelector')\n","plt.plot(x_axis, spark_acc_UnivariateFeatureSelector, label='spark_UnivariateFeatureSelector')\n","plt.plot(x_axis, sklearn_acc_chi2, label='sklearn_chi2')\n","plt.plot(x_axis, sklearn_acc_mutual_info_regression, label='sklearn_mutual_info_regression')\n","plt.ylim(0 , 1.1)\n","plt.title(\"Features vs Accuracy\")\n","plt.xlabel('Number of Features')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6591f51d-fbfc-485a-85cc-042cc603a503","showTitle":false,"title":""}},"outputs":[],"source":["plt.plot(x_axis, spark_time_ChiSqSelector, label='spark_ChiSqSelector')\n","plt.plot(x_axis, sklearn_time_chi2, label='sklearn_chi2')\n","plt.plot(x_axis, spark_time_UnivariateFeatureSelector, label='spark_UnivariateFeatureSelector')\n","plt.plot(x_axis, sklearn_time_mutual_info_regression, label='sklearn_mutual_info_regression')\n","plt.title(\"Features vs Execution Time\")\n","plt.xlabel('Number of Features')\n","plt.ylabel('Execution Time in Seconds')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8e80463d-9784-4907-9c33-3fafeb0ad482","showTitle":false,"title":""}},"outputs":[],"source":["plt.plot(x_axis, spark_acc_ChiSqSelector, label='spark_ChiSqSelector')\n","plt.plot(x_axis, sklearn_acc_chi2, label='sklearn_chi2')\n","plt.ylim(0 , 1.1)\n","plt.title(\"Features vs Accuracy\")\n","plt.xlabel('Number of Features')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"df4bb01e-8bc0-40f3-8d12-ef10d050c04b","showTitle":false,"title":""}},"outputs":[],"source":["plt.plot(x_axis, spark_time_ChiSqSelector, label='spark_ChiSqSelector')\n","plt.plot(x_axis, sklearn_time_chi2, label='sklearn_chi2')\n","plt.title(\"Features vs Execution Time\")\n","plt.xlabel('Number of Features')\n","plt.ylabel('Execution Time in Seconds')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8d988194-3d22-4ba7-9127-b017122c77de","showTitle":false,"title":""}},"outputs":[],"source":["plt.plot(x_axis, spark_acc_UnivariateFeatureSelector, label='spark_UnivariateFeatureSelector')\n","plt.plot(x_axis, sklearn_acc_mutual_info_regression, label='sklearn_mutual_info_regression')\n","plt.ylim(0 , 1.1)\n","plt.title(\"Features vs Accuracy\")\n","plt.xlabel('Number of Features')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e5f4b76c-adae-45dd-8cca-2a708222b524","showTitle":false,"title":""}},"outputs":[],"source":["plt.plot(x_axis, spark_time_UnivariateFeatureSelector, label='spark_UnivariateFeatureSelector')\n","plt.plot(x_axis, sklearn_time_mutual_info_regression, label='sklearn_mutual_info_regression')\n","plt.title(\"Features vs Execution Time\")\n","plt.xlabel('Number of Features')\n","plt.ylabel('Execution Time in Seconds')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"37fff42e-4c69-430b-b72f-b94fba0ba454","showTitle":false,"title":""}},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"BigDataFeatureSelection","notebookOrigID":4408804215311919,"widgets":{}},"interpreter":{"hash":"b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
